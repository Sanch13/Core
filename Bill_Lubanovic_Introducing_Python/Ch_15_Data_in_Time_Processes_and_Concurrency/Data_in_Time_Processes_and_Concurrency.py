import os, time
import subprocess
import multiprocessing

"""Ваша операционная система создает один процесс, который использует системные ресурсы 
(центральный процессор, память,место на диске) и структуры данных в ядре операционной системы
(файлы и сетевыесоединения, статистику использования и т. д.). Процесс изолирован от других 
процессов — он не может видеть, что делают другие процессы, или мешать им.Операционная система 
отслеживает все запущенные процессы, выделяя каждому из них немного времени и затем переключаясь
на другие, для того чтобы справедливо распределять работу и реагировать на действия пользователя.
Модуль стандартной библиотеки os предоставляет общий способ доступа к определенной системной
информации. Следующие функции получают идентификатор процесса и текущую рабочую папку запущенного
интерпретатора Python
"""
# print(os.getpid())  # идентификатор процесса 12832
# print(os.getcwd())  # E:\Projects\Core_Python\Ch_15_Data_in_Time_Processes_and_Concurrency
"""Создаем процесс с помощью модуля subprocess Все программы, с которыми вы сталкивались до 
этого момента, представляли собой отдельные процессы. Запускать и останавливать другие существующие
в Python программы можно, используя модуль subprocess из стандартной библиотеки."""
# print(subprocess.getoutput('date'))

"""Убиваем процесс, используя функцию terminate(). Если вы создали один или несколько процессов,
а теперь по какой-то причине хотите их завершить  используйте функцию terminate()."""
# def whoami(name):
#     print("I'm %s, in process %s" % (name, os.getpid()))
#
# def loopy(name):
#     whoami(name)
#     start = 1
#     stop = 1000000
#     for num in range(start, stop):
#         print("\tNumber %s of %s. Honk!" % (num, stop))
#         time.sleep(1)
#
# if __name__ == "__main__":
#     whoami("main")
#     p = multiprocessing.Process(target=loopy, args=("loopy",))
#     p.start()
#     time.sleep(5)
#     p.terminate()

"""Получаем системную информацию с помощью модуля os 
Стандартный пакет os предоставляет подробную информацию о вашей системе и позволяет управлять 
некоторыми функциями, запуская скрипт, написанный на Python, от лица привилегированного 
пользователя (например, администратора)."""
# print(os.name, os.path) # nt <module 'ntpath' from 'C:\\Python39\\lib\\ntpath.py'>
"""Имеется также полезная функция system(), которая выполняет командную строку так, как если
 бы вы ввели ее в консоли"""
# os.system('shutdown -s -t 3600')
# os.system('shutdown -a')

"""$ pip install invoke
Одним из вариантов использования пакета invoke является возможность сделать
функции доступными в качестве аргументов командной строки."""
from invoke import task

@task
def mytime(ctx):
    import time
    now = time.time()
    time_str = time.asctime(time.localtime(now))
    print("Local time is", time_str)

"""Аргумент ctx — первый аргумент для каждой преобразуемой функции, но используется он
 только самим пакетом invoke. Неважно, с каким именем, но этот аргумент там должен быть.
Используйте аргументы –l или –list, чтобы увидеть, какие задачи доступны"""
# $ invoke mytime
# Local time is Thu May 2 13:16:23 2019
""". Для получения более подробной информации обратитесь к документации 
(http://docs.pyinvoke.org/en/stable/)."""


""" Параллелизм
Когда речь идет о компьютерах, находиться в ожидании приходится по одной
из двух причин:
- из-за ограничения ввода-вывода. Это наиболее распространенная причина. Процессоры
компьютеров безумно быстры — в сотни раз быстрее, чем компьютерная память, и в 
тысячи — чем диски или сети;
- из-за ограничения процессора. Это случается при выполнении таких объемных
задач, как научные или графические расчеты.
C Параллелизмом связаны еще два термина:
- синхронность — одна вещь следует за другой, как гусята, семенящие за родителями;
- асинхронность — задачи независимы, как гуси, которые плавают в пруду.
Ну а если вы не можете повлиять на то, что долго выполняется? Например, на
загрузку файла на сервер, на изменение размеров изображения или запрос к базе
данных? Вы больше не можете делать это при помощи синхронного кода вашего
веб-сервера, поскольку кто-то уже ждет.
Если вам нужно выполнить несколько задач как можно быстрее на одном компьютере, 
вы можете сделать их независимыми, и тогда медленные задачи не будут
блокировать остальные. Идея заключается в том, чтобы заставить их работать друг с другом. Наличие
любого общего элемента управления или состояния означает, что будут возникать
узкие места. Особый подход нужен для обработки ошибок, поскольку конкурентные
вычисления сложнее обычных. Многое может пойти не так, и ваши шансы на успех
будут ниже. Какие же методы могут помочь справиться с этими сложностями? Начнем с хорошего 
способа для управления несколькими задачами — это очереди.
"""

"""Очередь похожа на список: элементы добавляются с одного ее конца и удаляются
с другого. Часто такой принцип называют FIFO (first in, first out — «первым пришел,
первым ушел»). В целом, очереди переносят сообщения, которые могут содержать любую
информацию. В данном случае нас интересуют очереди для распределенного
управления задачами, также известные как рабочие очереди или очереди заданий.
Каждая тарелка из раковины выдается доступному мойщику: он ее моет
и передает первому доступному сушильщику. Тот, в свою очередь, отдает тарелку
первому доступному работнику, в чьи обязанности входит убрать ее в сторону.
Этот процесс может быть синхронным (работники сначала ждут, когда им дадут
тарелку, а потом ждут, когда освободится следующий в очереди работник) или
асинхронным (посуда поступает от работников с разной скоростью). Если у вас
есть достаточно работников и они трудятся в одном темпе, задача будет выполнена
гораздо быстрее.
У модуля multiprocessing есть очереди и других типов: узнать о них вы можете из документации
 (https://docs.python.org/3/library/multiprocessing.html).
"""

"""Поток запускается внутри процесса и имеет доступ ко всему, что находится в процессе, — это
можно сравнить с раздвоением личности. Модуль multiprocessing имеет «кузена» по имени threading,
который использует потоки вместо процессов. Различие между модулями multiprocessing и threading
 заключается в том, что модуль threading не имеет функции terminate(). Не существует простого
 способа завершить запущенный поток, поскольку это может вызвать разнообразные проблемы в коде
и, возможно, даже в пространственно-временном континууме.
Потоки могут быть опасны. Как и управление памятью вручную в таких языках,
как С и С++, они могут вызвать появление ошибок, которые ужасно трудно найти
и исправить. Для того чтобы задействовать потоки, весь код программы — и код
внешних библиотек, которые он использует, — должен быть потокобезопасным. 
Потоки могут быть полезны и безопасны, когда речь не идет о глобальных данных. В частности, 
рекомендуется использовать потоки для экономии времени при ожидании завершения некоторых операций 
ввода/вывода. В этом случае потокам не нужно сражаться за данные, поскольку у каждого из 
них имеется свой наборпеременных.
еременных.
Но у потоков иногда есть веские причины для изменения глобальных данных.
Фактически самая распространенная причина для использования нескольких потоков — это возможность
 разделить между ними работу над определенными данными,
поэтому ожидается, что какие-то данные будут изменены.
Классический способ разделить данные безопасно — разместить программную
блокировку перед изменением переменной в потоке. Это позволит оградить ее значение от
других потоков и внести свои изменения. 
"""

"""В Python потоки не ускоряют задачи, связанные с ограничениями процессора, из-за 
одной детали реализации стандартной системы Python, которая называется Global 
Interpreter Lock (GIL). Она предназначена для того, чтобы избежать потоковых проблем
 в интерпретаторе Python, и действительно может замедлить многопоточную 
программу по сравнению с однопоточной или даже многопроцессорной версией."""

"""
Итак, для Python рекомендации следующие:
- используйте потоки для задач, связанных с ограничениями ввода-вывода;
- используйте процессы, сетевые вычисления или события (которые мы рассмотрим в 
следующем подразделе) для задач, связанных с ограничениями процессора."""

"""Как вы только что видели, использование потоков или нескольких процессов требует отслеживания
 большого количества деталей. Модуль concurrent.futures был
добавлен в стандартную библиотеку в версии Python 3.2 для того, чтобы упростить
эту задачу. Он позволяет вам спроектировать асинхронный пул так называемых
работников с помощью потоков (с ограничением по вводу-выводу) и процессов
(с ограничением по ЦП). Вы получаете объект типа future, который позволяет отслеживать
 состояние заданий и собирать результаты работы. Вы можете использовать модуль concurrent.futures
всякий раз, когда вам нужно запустить несколько конкурирующих задач, например таких, как:
- поиск (crawling) URL в Интернете;
- обработка файлов, например изменение размера изображений;
- вызов API какой-либо службы.
Как обычно, в документации (https://docs.python.org/3/library/concurrent.futures.html) вы
можете найти дополнительную информацию с большим количеством технических деталей."""

"""Зеленые потоки и gevent. Как вы уже видели, разработчики стремятся избежать медленных мест в
программах, запуская их в отдельных потоках или процессах. Примером такого дизайна
является веб-сервер Apache. Альтернативой является программирование, основанное на событиях
(eventbased programming). Программа, основанная на событиях, запускает центральный
цикл обработки событий, раздает задачи и повторяет цикл. Так устроен веб-сервер
NGINX, работающий быстрее, чем Apache. Библиотека gevent основана на событиях и позволяет достичь
 следующего: вы пишете обычный императивный код, и волшебным образом его части превращаются
в сопрограммы. Они похожи на генераторы, которые могут взаимодействовать друг
с другом и отслеживать свое текущее состояние. Библиотека gevent модифицирует
многие стандартные объекты Python, такие как socket, для того чтобы использовать
их механизм вместо блокирования. Это не работает для кода надстроек Python, который написан на С,
 например для некоторых драйверов баз данных.
Вы можете установить библиотеку gevent с помощью pip:
$ pip install gevent
"""

"""Существует два других популярных фреймворка, основанных на событиях, — 
tornado (http://www.tornadoweb.org/) и gunicorn (http://gunicorn.org/). Они помогают 
обрабатывать события на низком уровне, а также предоставляют быстрый вебсервер. Их стоит
 рассмотреть, если вы хотите создать быстрый сайт без применения 
традиционных веб-серверов, таких как Apache.
"""

"""twisted (http://twistedmatrix.com/trac/) — это асинхронный фреймворк, управляемый
событиями, для работы с сетями. Вы подключаете функции к таким событиям, как
получение данных или закрытие соединения, и функции вызываются, когда событие
происходит. В данном случае речь идет о функциях обратного вызова. По мере роста
приложения некоторым разработчикам бывает сложнее управлять кодом, основанным на функциях
обратного вызова. wisted — это крупный пакет, который поддерживает множество интернет-протоколов
на базе TCP и UDP."""

"""Redis
Рассмотрим еще один подход к очередям, которые могут запускаться на одной машине или во всей сети.
Иногда даже для нескольких процессов и/или потоков одной машины бывает недостаточнo. 
Создать очередь можно с помощью списка Redis. Сервер Redis работает на одной
машине, на которой могут быть запущены и клиенты. Возможно также, что никакие
клиенты на ней не запускаются, а остальные машины получают доступ к серверу
по сети. В любом случае клиент общается с сервером с помощью протокола TCP.
Один или несколько клиентов-провайдеров помещают сообщения в конец списка.
Один или несколько клиентов-работников наблюдают за списком и используют
операцию «блокирующее выталкивание» (blocking pop). Если список пуст, то все
они просто тратят время впустую. Как только сообщение появляется, его получает
первый ожидающий работник.

С увеличением числа работающих элементов растет вероятность сбоев в работе.
есть некоторые приемы:
- Запустить и забыть. Просто передавайте обработанные объекты дальше и не заботьтесь о 
последствиях, даже если там никого нет.
- Запрос — ответ. Мойщик получает подтверждение от сушильщика, а сушильщик — от того, 
кто откладывает посуду в сторону. Все это выполняется для каждой тарелки.
- Регулирование нагрузки. Этот прием указывает самому быстрому работнику притормозить, если 
один из работников, стоящих после него, не поспевает за ним.
"""

"""
В реальных системах вам нужно внимательно следить за тем, чтобы все работники успевали за графиком,
 в противном случае вы услышите звук бьющейся посуды.
Вы можете добавлять в список ожидания новые задачи, а какой-то процесс будет
доставать из этого списка последнее сообщение и помещать его в список обработки.
Обработанное сообщение будет удалено из списка обработки и добавлено в список
завершенных задач. Это позволит вам узнать, какие задачи не были выполнены
или затрачивают слишком много времени. Вы можете сделать это самостоятельно
с помощью Redis или использовать систему, которую кто-то другой уже написал
и протестировал. Некоторые основанные на Python пакеты для работы с очередями
(часть из них используют Redis) позволяют удобно управлять процессом:
- celery (http://www.celeryproject.org/) может выполнять распределенные задачи
как синхронно, так и асинхронно, используя рассмотренные нами методы —
multiprocessing, gevent и др.;
- rq (http://python-rq.org/) — это библиотека Python для очередей задач, также основанная на Redis.
"""

# TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS   TASKS
import random


def says():
    wait = random.random()
    time.sleep(wait)
    print(f"I have been waiting {wait:.03} seconds and local time {time.strftime('%H:%M:%S')}")


if __name__ == "__main__":
    for n in range(3):
        p = multiprocessing.Process(target=says)
        p.start()
###################################################################################################





